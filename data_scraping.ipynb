{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.errors\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: t89aiVLgf1k \n",
      " Added sucessfully\n",
      "Video ID: H3jaIhSj23E \n",
      " Added sucessfully\n",
      "Video ID: RToUZJ0l7Pk \n",
      " Added sucessfully\n",
      "Video ID: 7J7aJtGphVs \n",
      " Added sucessfully\n",
      "Video ID: nie_LASiZJ0 \n",
      " Added sucessfully\n",
      "Video ID: 9H2KUzLCFTM \n",
      " Added sucessfully\n",
      "Video ID: YmWgp4K9XuU \n",
      " Added sucessfully\n",
      "Video ID: xPE7-PRL0M8 \n",
      " Added sucessfully\n",
      "Video ID: NWzBX3OP234 \n",
      " Added sucessfully\n",
      "Video ID: sj-iCoPQN78 \n",
      " Added sucessfully\n"
     ]
    }
   ],
   "source": [
    "api__name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "API_KEY = \"AIzaSyCvamWK3M65RDSElOPlTG8SU1uqtlnrZOs\"\n",
    "csv_file = \"youtube_comments.csv\"\n",
    "video_ids = ['t89aiVLgf1k', 'H3jaIhSj23E', 'RToUZJ0l7Pk', '7J7aJtGphVs', 'nie_LASiZJ0', '9H2KUzLCFTM', 'YmWgp4K9XuU', 'xPE7-PRL0M8', 'NWzBX3OP234', 'sj-iCoPQN78']\n",
    "#! filter to english and try to use models with only english language\n",
    "if not os.path.exists(csv_file):\n",
    "    for video_id in video_ids:\n",
    "        youtube = googleapiclient.discovery.build(\n",
    "            api__name, api_version, developerKey=API_KEY)\n",
    "        max_results_per_request = 100\n",
    "        total_comments_to_extract = 2000\n",
    "        comments = []\n",
    "        \n",
    "        next_page_token = None # extracts pagetoken to remember the last page token to extract new comments\n",
    "        \n",
    "        while len(comments) < total_comments_to_extract:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=max_results_per_request,\n",
    "                pageToken=next_page_token,\n",
    "                \n",
    "            )\n",
    "            response = request.execute()\n",
    "            \n",
    "            \n",
    "            \n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comments.append([\n",
    "                    comment['authorDisplayName'],\n",
    "                    # comment['publishedAt'],\n",
    "                    # comment['updatedAt'],\n",
    "                    # comment['likeCount'],\n",
    "                    comment['textDisplay']\n",
    "                ])\n",
    "                \n",
    "            next_page_token = response.get('nextPageToken')\\\n",
    "                \n",
    "            # if no nextpage after extracting the comments breaking the loop\n",
    "            if not next_page_token:\n",
    "                break\n",
    "        if not os.path.exists(csv_file):\n",
    "            with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Author', 'Comment'])\n",
    "                writer.writerows(comments)\n",
    "            print(f\"Video ID: {video_id} \\n Added sucessfully\")\n",
    "        else:\n",
    "            with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Author', 'Comment'])\n",
    "                writer.writerows(comments)\n",
    "            print(f\"Video ID: {video_id} \\n Added sucessfully\")\n",
    "else:\n",
    "     print(\"CSV file already exists. The code will not run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unhappy Bacon</td>\n",
       "      <td>My friends loved it and agreed with everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amadanman85</td>\n",
       "      <td>I vow never ever too see this Movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Chambers</td>\n",
       "      <td>The real world.... A thought experiment......ðŸ‡¬ðŸ‡§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Irisdew</td>\n",
       "      <td>I really enjoyed the movie and didn&amp;#39;t find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ben</td>\n",
       "      <td>I hope sheâ€™s joking. Itâ€™s a movie about Barbie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18329</th>\n",
       "      <td>Daz Hatz</td>\n",
       "      <td>It makes you want to puke doesn&amp;#39;t it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18330</th>\n",
       "      <td>4EVERSEEKING WISDOM</td>\n",
       "      <td>If Cleopatra was supposed to be so beautiful t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18331</th>\n",
       "      <td>Senni</td>\n",
       "      <td>what a time we live in when the &amp;quot;Asterix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18332</th>\n",
       "      <td>Krystal Myth</td>\n",
       "      <td>Egypt deserves to win their case against corpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18333</th>\n",
       "      <td>Hexx Kana</td>\n",
       "      <td>watching your video.. i came to ask myself a f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18334 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Author                                            Comment\n",
       "0            Unhappy Bacon  My friends loved it and agreed with everything...\n",
       "1              Amadanman85               I vow never ever too see this Movie.\n",
       "2               A Chambers    The real world.... A thought experiment......ðŸ‡¬ðŸ‡§\n",
       "3                  Irisdew  I really enjoyed the movie and didn&#39;t find...\n",
       "4                      Ben  I hope sheâ€™s joking. Itâ€™s a movie about Barbie...\n",
       "...                    ...                                                ...\n",
       "18329             Daz Hatz          It makes you want to puke doesn&#39;t it.\n",
       "18330  4EVERSEEKING WISDOM  If Cleopatra was supposed to be so beautiful t...\n",
       "18331                Senni  what a time we live in when the &quot;Asterix ...\n",
       "18332         Krystal Myth  Egypt deserves to win their case against corpo...\n",
       "18333            Hexx Kana  watching your video.. i came to ask myself a f...\n",
       "\n",
       "[18334 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('youtube_comments.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refrence for sentiment label model [https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest] </br>\n",
    "Refrence for language detection model [https://huggingface.co/qanastek/51-languages-classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_labels added successfully.\n",
      "language_label added successfully.\n"
     ]
    }
   ],
   "source": [
    "# using transformer from hugging face\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipelines\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "\n",
    "def get_sentiment_label(comment):\n",
    "    result = classifier(comment)\n",
    "    label = result[0]['label']\n",
    "    return label\n",
    "\n",
    "def get_language_det(comment):\n",
    "    result = lang_classifier(comment)\n",
    "    lang_det = result[0]['label']\n",
    "    return lang_det\n",
    "    \n",
    "if 'sentiment_label' not in dataframe.columns:\n",
    "    classifier =  pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\", max_length=512, truncation = True, truncation_strategy = 'longest_first')\n",
    "    # Applying the classification label to the dataframe\n",
    "    dataframe['sentiment_label'] = dataframe['Comment'].apply(get_sentiment_label)\n",
    "    dataframe.to_csv('youtube_comments.csv', index=False) # saving the classified labels to the csv again.\n",
    "    print(\"sentiment_labels added successfully.\")\n",
    "    \n",
    "if 'language_detected' not in dataframe.columns:\n",
    "    model_name = 'qanastek/51-languages-classifier'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    lang_classifier = lang_classifier = pipeline(\"text-classification\", model=model_name, tokenizer=model_name,max_length=512, truncation = True, truncation_strategy = 'longest_first')\n",
    "\n",
    "    # Applying the classification label to the dataframe\n",
    "    dataframe['language_detected'] = dataframe['Comment'].apply(get_language_det)\n",
    "    dataframe.to_csv('youtube_comments.csv', index=False) # saving the classified labels to the csv again.\n",
    "    print(\"language_label added successfully.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Dataframe already labeled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>language_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unhappy Bacon</td>\n",
       "      <td>My friends loved it and agreed with everything...</td>\n",
       "      <td>positive</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amadanman85</td>\n",
       "      <td>I vow never ever too see this Movie.</td>\n",
       "      <td>negative</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Chambers</td>\n",
       "      <td>The real world.... A thought experiment......ðŸ‡¬ðŸ‡§</td>\n",
       "      <td>neutral</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Irisdew</td>\n",
       "      <td>I really enjoyed the movie and didn&amp;#39;t find...</td>\n",
       "      <td>positive</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ben</td>\n",
       "      <td>I hope sheâ€™s joking. Itâ€™s a movie about Barbie...</td>\n",
       "      <td>positive</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18329</th>\n",
       "      <td>Daz Hatz</td>\n",
       "      <td>It makes you want to puke doesn&amp;#39;t it.</td>\n",
       "      <td>negative</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18330</th>\n",
       "      <td>4EVERSEEKING WISDOM</td>\n",
       "      <td>If Cleopatra was supposed to be so beautiful t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18331</th>\n",
       "      <td>Senni</td>\n",
       "      <td>what a time we live in when the &amp;quot;Asterix ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18332</th>\n",
       "      <td>Krystal Myth</td>\n",
       "      <td>Egypt deserves to win their case against corpo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18333</th>\n",
       "      <td>Hexx Kana</td>\n",
       "      <td>watching your video.. i came to ask myself a f...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18334 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Author                                            Comment  \\\n",
       "0            Unhappy Bacon  My friends loved it and agreed with everything...   \n",
       "1              Amadanman85               I vow never ever too see this Movie.   \n",
       "2               A Chambers    The real world.... A thought experiment......ðŸ‡¬ðŸ‡§   \n",
       "3                  Irisdew  I really enjoyed the movie and didn&#39;t find...   \n",
       "4                      Ben  I hope sheâ€™s joking. Itâ€™s a movie about Barbie...   \n",
       "...                    ...                                                ...   \n",
       "18329             Daz Hatz          It makes you want to puke doesn&#39;t it.   \n",
       "18330  4EVERSEEKING WISDOM  If Cleopatra was supposed to be so beautiful t...   \n",
       "18331                Senni  what a time we live in when the &quot;Asterix ...   \n",
       "18332         Krystal Myth  Egypt deserves to win their case against corpo...   \n",
       "18333            Hexx Kana  watching your video.. i came to ask myself a f...   \n",
       "\n",
       "      sentiment_label language_detected  \n",
       "0            positive             en-US  \n",
       "1            negative             en-US  \n",
       "2             neutral             en-US  \n",
       "3            positive             en-US  \n",
       "4            positive             en-US  \n",
       "...               ...               ...  \n",
       "18329        negative             en-US  \n",
       "18330        negative             en-US  \n",
       "18331         neutral             en-US  \n",
       "18332        negative             en-US  \n",
       "18333         neutral             en-US  \n",
       "\n",
       "[18334 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = dataframe[dataframe['language_detected'] == 'en-US']\n",
    "selected_columns = ['Author', 'Comment', 'sentiment_label']\n",
    "filtered_data = filtered_data[selected_columns]\n",
    "filtered_data.to_csv('youtube_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unhappy Bacon</td>\n",
       "      <td>My friends loved it and agreed with everything...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amadanman85</td>\n",
       "      <td>I vow never ever too see this Movie.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Chambers</td>\n",
       "      <td>The real world.... A thought experiment......ðŸ‡¬ðŸ‡§</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Irisdew</td>\n",
       "      <td>I really enjoyed the movie and didn&amp;#39;t find...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ben</td>\n",
       "      <td>I hope sheâ€™s joking. Itâ€™s a movie about Barbie...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17500</th>\n",
       "      <td>Daz Hatz</td>\n",
       "      <td>It makes you want to puke doesn&amp;#39;t it.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17501</th>\n",
       "      <td>4EVERSEEKING WISDOM</td>\n",
       "      <td>If Cleopatra was supposed to be so beautiful t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17502</th>\n",
       "      <td>Senni</td>\n",
       "      <td>what a time we live in when the &amp;quot;Asterix ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17503</th>\n",
       "      <td>Krystal Myth</td>\n",
       "      <td>Egypt deserves to win their case against corpo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17504</th>\n",
       "      <td>Hexx Kana</td>\n",
       "      <td>watching your video.. i came to ask myself a f...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17505 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Author                                            Comment  \\\n",
       "0            Unhappy Bacon  My friends loved it and agreed with everything...   \n",
       "1              Amadanman85               I vow never ever too see this Movie.   \n",
       "2               A Chambers    The real world.... A thought experiment......ðŸ‡¬ðŸ‡§   \n",
       "3                  Irisdew  I really enjoyed the movie and didn&#39;t find...   \n",
       "4                      Ben  I hope sheâ€™s joking. Itâ€™s a movie about Barbie...   \n",
       "...                    ...                                                ...   \n",
       "17500             Daz Hatz          It makes you want to puke doesn&#39;t it.   \n",
       "17501  4EVERSEEKING WISDOM  If Cleopatra was supposed to be so beautiful t...   \n",
       "17502                Senni  what a time we live in when the &quot;Asterix ...   \n",
       "17503         Krystal Myth  Egypt deserves to win their case against corpo...   \n",
       "17504            Hexx Kana  watching your video.. i came to ask myself a f...   \n",
       "\n",
       "      sentiment_label  \n",
       "0            positive  \n",
       "1            negative  \n",
       "2             neutral  \n",
       "3            positive  \n",
       "4            positive  \n",
       "...               ...  \n",
       "17500        negative  \n",
       "17501        negative  \n",
       "17502         neutral  \n",
       "17503        negative  \n",
       "17504         neutral  \n",
       "\n",
       "[17505 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"youtube_comments.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Comment, dtype: object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Comment'][df['Author']=='Chantal Chabot'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
