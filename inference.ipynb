{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html, json, re\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from joblib import load\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./slang_dict.json\",'r') as f:\n",
    "    slang_dict = json.load(f)\n",
    "    \n",
    "with open(\"./emoji_dic.json\",'r') as f:\n",
    "    emoji_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # converting html codes \n",
    "    decoded_text = html.unescape(text)\n",
    "    decoded_text = decoded_text.lower()\n",
    "    # match strings starting with 'http'\n",
    "    text = re.sub(r'http\\S+', '', decoded_text)\n",
    "    # match strings start with '<' and end with '>'\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # remove emoji\n",
    "    for em, meaning in emoji_dict.items():\n",
    "        text = text.replace(em, meaning)\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    #standard preprocessing technique\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove punctuation\n",
    "    punctuation_removed = [word for word in tokens if word not in list(string.punctuation)]\n",
    "    # lemmatization\n",
    "    lemmatized_text = [WordNetLemmatizer().lemmatize(word) for word in punctuation_removed]\n",
    "    text =  ' '.join(lemmatized_text)\n",
    "\n",
    "    ## removing slangs\n",
    "    words = text.split()\n",
    "    corrected_words = [slang_dict.get(word, word) for word in words]\n",
    "    text = ' '.join(corrected_words)\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    return text \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "\n",
    "# # Check if CUDA is available\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"Using CPU\")\n",
    "\n",
    "# # Load pre-trained BERT model and tokenizer\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True).to(device)\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_bert_embedding(comment):\n",
    "#     inputs = bert_tokenizer.encode_plus(\n",
    "#         comment,\n",
    "#         add_special_tokens=True,\n",
    "#         return_tensors='pt',\n",
    "#         max_length=128,\n",
    "#         pad_to_max_length=True,\n",
    "#         return_attention_mask=True\n",
    "#     )\n",
    "    \n",
    "#     # Move input tensors to the GPU\n",
    "#     inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = bert_model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "#     # Extract the [CLS] token's embedding and move it back to the CPU\n",
    "#     cls_embedding = outputs['last_hidden_state'][:, 0, :].squeeze().cpu().numpy()\n",
    "#     return cls_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "\n",
    "def get_tfidf_embedding(comment):\n",
    "    # Ensure comment is in list format\n",
    "    if isinstance(comment, str):\n",
    "        comment = [comment]\n",
    "    # Transform the input text using the loaded tfidf_vectorizer\n",
    "    input_text_tfidf = loaded_tfidf_vectorizer.transform(comment)\n",
    "    return input_text_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model from the file\n",
    "loaded_model = load('svm_classifier.joblib')\n",
    "def infer(X):\n",
    "   X = X.reshape(1, -1)\n",
    "   return loaded_model.predict(X) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = \"\"\"Where do I even begin with the Oppenheimer movie? It's a perplexing mess of a film that fails to capture the essence of its subject matter and leaves the audience scratching their heads in confusion. With high expectations due to its talented cast and promising premise, this movie ultimately disappoints on every level.\n",
    "\n",
    "First and foremost, the pacing is an absolute nightmare. The movie meanders aimlessly, dragging out scenes that add little to the plot and leaving essential elements underdeveloped. It's almost as if the filmmakers had no idea how to structure the narrative or maintain a cohesive flow. As a result, the movie feels like a jumbled collection of disconnected events that leave viewers struggling to make sense of the story.\n",
    "\n",
    "The characters in Oppenheimer are equally underwhelming. Despite the exceptional actors involved, their performances are hampered by a lack of depth and poorly written dialogues. The titular character, J. Robert Oppenheimer, comes across as one-dimensional and devoid of real personality or emotional resonance. Supporting characters receive even less attention, leaving us indifferent to their fates and unable to invest in their arcs.\n",
    "\n",
    "The film's attempts at historical accuracy are laughable at best. While some creative liberties are expected in any biographical movie, Oppenheimer takes it to an extreme. The inaccuracies and distortions of actual events not only disrespect the legacy of those involved but also undermine the film's credibility. The filmmakers were more interested in sensationalism than telling a compelling and fact-based story.\n",
    "\n",
    "Perhaps the most egregious aspect of the Oppenheimer movie is its lack of a coherent message or thematic depth. It raises significant moral and ethical questions about the development of nuclear weapons and their consequences, but it never delves into these issues with any real substance. Instead, the movie superficially glazes over these crucial aspects, leaving viewers with a sense of emptiness and missed opportunities.\n",
    "\n",
    "The cinematography and direction do little to salvage the film's shortcomings. The visual style lacks creativity, and the director seems to rely on tired and overused cinematic clich√©s. The lack of a distinct visual identity only adds to the overall mediocrity of the movie.\n",
    "\n",
    "In conclusion, the Oppenheimer movie is a colossal disappointment. Its weak storytelling, poorly developed characters, historical inaccuracies, and lack of a compelling message all contribute to a film that is an absolute failure. Save your time and money and skip this cinematic disaster. There are far better biographical dramas out there that do justice to their subjects and deliver a more engaging and coherent experience. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment(review):\n",
    "    processed = preprocess(review)\n",
    "    features = get_tfidf_embedding(processed)\n",
    "    output = infer(features)\n",
    "    return output\n",
    "\n",
    "get_sentiment(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Define the function that will determine the sentiment.\n",
    "def get_sentiment_button(review):    \n",
    "    return get_sentiment(review)\n",
    "\n",
    "# Function to be called when the \"Get Sentiment\" button is pressed.\n",
    "def on_button_press():\n",
    "    review = entry.get(\"1.0\", \"end-1c\")  # Get text from the entry widget.\n",
    "    sentiment = get_sentiment_button(review)\n",
    "    messagebox.showinfo(\"Sentiment Result\", f\"The sentiment is: {sentiment}\")\n",
    "\n",
    "# Create the main window.\n",
    "root = tk.Tk()\n",
    "root.title(\"Sentiment Analysis\")\n",
    "\n",
    "# Create and pack widgets.\n",
    "label = tk.Label(root, text=\"Enter your review:\")\n",
    "label.pack(pady=20)\n",
    "\n",
    "entry = tk.Text(root, height=10, width=50)\n",
    "entry.pack(pady=20)\n",
    "\n",
    "button = tk.Button(root, text=\"Get Sentiment\", command=on_button_press)\n",
    "button.pack(pady=20)\n",
    "\n",
    "# Run the application.\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
